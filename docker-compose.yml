services:
  redis-server:
    image: redis:7.2.4-alpine
    ports:
      - "6379:6379"
    networks:
      - a2_comp_escalavel_default

  spark-master:
    image: bitnami/spark:3.5.1
    # command: /opt/bitnami/spark/bin/spark-submit-runner.sh /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080" # Spark Master Web UI
      - "7077:7077" # Spark Master internal communication
    environment:
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - a2_comp_escalavel_default

  spark-worker:
    image: bitnami/spark:3.5.1
    # command: /opt/bitnami/spark/bin/spark-submit-runner.sh /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_MODE=worker
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - a2_comp_escalavel_default

  # Servi√ßo para o job Spark
  spark-batch-processor:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - spark-master
      - redis-server
    environment:
      SPARK_MASTER_URL: spark://spark-master:7077
      REDIS_HOST: redis-server
      REDIS_PORT: 6379
      MONITOR_INTERVAL_SECONDS: 10
      LIST_THRESHOLDS_JSON: |
          {"raw_travel_data_list": 50, "raw_flights": 50}

    entrypoint: ["/opt/bitnami/python/bin/python", "main.py"]
    networks:
      - a2_comp_escalavel_default

networks:
  a2_comp_escalavel_default:

  # spark-app:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   depends_on:
  #     - spark-master
  #     - redis-server
  #   ports:
  #     - "5000:5000"
  #   environment:
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - REDIS_HOST=redis-server
  #   networks:
  #     - a2_comp_escalavel_default

  # redis-list-monitor:
  #   build: ./redismonitor
  #   depends_on:
  #     - redis-server
  #     - spark-app
  #   environment:
  #     - REDIS_HOST=redis-server
  #     - REDIS_PORT=6379
  #     - SPARK_APP_URL=http://spark-app:5000/trigger-spark-job
  #     - MONITOR_INTERVAL_SECONDS=10
  #     - LIST_THRESHOLDS_JSON='{"raw_travel_data_list": 50, "raw_flights": 50}'
  #   networks:
  #     - a2_comp_escalavel_default